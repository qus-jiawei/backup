<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration  xmlns:xi="http://www.w3.org/2001/XInclude">
   <xi:include href="hdfs-site.private.xml"/>
   <property>
    <name>dfs.nameservices</name>
    <value>{{hadoop['nameservice_id']}}</value>
  </property>
  <property>
   <name>dfs.ha.namenodes.{{hadoop['nameservice_id']}}</name>
   <value>nn1,nn2</value>
  </property>
  <property>
    <name>dfs.blocksize</name>
    <value>{{hadoop['dfs_blocksize']}}</value>
  </property>
  <property>
    <name>dfs.permissions.superusergroup</name>
    <value>{{hadoop['dfs_permissions_superusergroup']}}</value>
  </property>
  <property>
    <name>dfs.ha.automatic-failover.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>ha.zookeeper.quorum</name>
    <value>{{groups.ZOOKEEPER | join(':' ~ hadoop['zookeeper_clientport'] + ',')}}:{{hadoop['zookeeper_clientport']}}</value>
  </property>

{% for host in groups['NAMENODE'] %}
  <property>
    <name>dfs.namenode.rpc-address.{{hadoop['nameservice_id']}}.nn{{loop.index}}</name>
    <value>{{host}}:{{hadoop['fs_default_FS_port']}}</value>
  </property>
{% endfor %}
{% for host in groups['NAMENODE'] %}
  <property>
    <name>dfs.namenode.http-address.{{hadoop['nameservice_id']}}.nn{{loop.index}}</name>
    <value>{{host}}:{{hadoop['dfs_namenode_http_address_port']}}</value>
  </property>
{% endfor %}
{% for host in groups['NAMENODE'] %}
  <property>
    <name>dfs.namenode.https-address.{{hadoop['nameservice_id']}}.nn{{loop.index}}</name>
    <value>{{host}}:{{hadoop['dfs_namenode_https_address_port']}}</value>
  </property>
{% endfor %}
  <property>
    <name>dfs.namenode.shared.edits.dir</name>
    <value>qjournal://{{groups.QJM | join(':' ~ hadoop['qjournal_port'] + ';')}}:{{hadoop['qjournal_port']}}/{{hadoop['nameservice_id']}}</value>
  </property>
  <property>
   <name>dfs.journalnode.edits.dir</name>
   <value>{{hadoop['dfs_journalnode_edits_dir']}}</value>
  </property>  
  <property>
    <name>dfs.namenode.edits.journal-plugin.qjournal</name>
    <value>org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager</value>
  </property>
  <property>
    <name>dfs.journalnode.rpc-address</name>
    <value>0.0.0.0:{{hadoop['qjournal_port']}}</value>
  </property>
  <property>
    <name>dfs.journalnode.http-address</name>
    <value>0.0.0.0:{{hadoop['qjournal_http_port']}}</value>
  </property>
  <property>
   <name>dfs.client.failover.proxy.provider.{{hadoop['nameservice_id']}}</name>
   <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>
 <property>
   <name>dfs.ha.fencing.methods</name>
   <value>{{hadoop['dfs_ha_fencing_methods']}}</value>
 </property>
 <property>
   <name>dfs.ha.fencing.ssh.private-key-files</name>
   <value>{{hadoop['dfs_ha_fencing_ssh_private-key-files']}}</value>
 </property>

<property>
    <name>dfs.ha.zkfc.port</name>
    <value>{{hadoop['dfs_ha_zkfc_port']}}</value>
  </property>
  
 <property>
    <name>dfs.datanode.address</name>
    <value>0.0.0.0:{{hadoop['dfs_datanode_address_port']}}</value>
  </property>
  <property>
    <name>dfs.datanode.http.address</name>
    <value>0.0.0.0:{{hadoop['dfs_datanode_http_address_port']}}</value>
  </property>
  <property>
    <name>dfs.datanode.ipc.address</name>
    <value>0.0.0.0:{{hadoop['dfs_datanode_ipc_address_port']}}</value>
  </property>
  <property>
    <name>dfs.replication</name>
    <value>{{hadoop['dfs_replication']}}</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>{{hadoop['dfs_namenode_name_dir'] | join(',')}}</value>
  </property>
  <property>
    <name>dfs.hosts</name>
    <value>{{hadoop_conf_dir}}/dfs_hosts_include.txt</value>
  </property>
  <property>
    <name>dfs.hosts.exclude</name>
    <value>{{hadoop_conf_dir}}/dfs_hosts_exclude.txt</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.txns</name>
    <value>1000000</value>
  </property>
  <property>
    <name>dfs.namenode.checkpoint.period</name>
    <value>3600</value>
  </property>
  <property>
    <name>dfs.namenode.replication.min</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.replication.max</name>
    <value>40</value>
  </property>
  <property>
    <name>dfs.namenode.plugins</name>
    <value></value>
  </property>
  <property>
    <name>dfs.namenode.handler.count</name>
    <value>256</value>
  </property>
  <property>
    <name>dfs.namenode.service.handler.count</name>
    <value>256</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir.restore</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.thrift.threads.max</name>
    <value>20</value>
  </property>
  <property>
    <name>dfs.thrift.threads.min</name>
    <value>10</value>
  </property>
  <property>
    <name>dfs.thrift.timeout</name>
    <value>60</value>
  </property>
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.namenode.safemode.threshold-pct</name>
    <value>0.999</value>
  </property>
  <property>
    <name>dfs.namenode.invalidate.work.pct.per.iteration</name>
    <value>0.32</value>
  </property>
  <property>
    <name>dfs.namenode.replication.work.multiplier.per.iteration</name>
    <value>2</value>
  </property>
  <property>
    <name>dfs.safemode.min.datanodes</name>
    <value>0</value>
  </property>
  <property>
    <name>dfs.namenode.safemode.extension</name>
    <value>30000</value>
  </property>
  <property>
    <name>dfs.client.use.datanode.hostname</name>
    <value>false</value>
  </property>
  <property>
    <name>fs.permissions.umask-mode</name>
    <value>066</value>
  </property>
  <property>
    <name>dfs.encrypt.data.transfer</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.encrypt.data.transfer.algorithm</name>
    <value>rc4</value>
  </property>
  <property>
    <name>dfs.datanode.hdfs-blocks-metadata.enabled</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.datanode.drop.cache.behind.writes</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.datanode.drop.cache.behind.reads</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.datanode.sync.behind.writes</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.datanode.readahead.bytes</name>
    <value>8388608</value>
  </property>
  <property>
    <name>dfs.datanode.fsdataset.volume.choosing.policy</name>
    <value>org.apache.hadoop.hdfs.server.datanode.fsdataset.RoundRobinVolumeChoosingPolicy</value>
  </property>
<property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>755</value>
  </property>
  <property>
    <name>dfs.datanode.handler.count</name>
    <value>64</value>
  </property>
  <property>
    <name>dfs.datanode.max.transfer.threads</name>
    <value>5120</value>
  </property>
  <property>
    <name>dfs.datanode.du.reserved</name>
    <value>{{hadoop['dfs_datanode_du_reserved']}}</value>
  </property>
  <property>
    <name>dfs.datanode.failed.volumes.tolerated</name>
    <value>{{hadoop['dfs_datanode_failed_volumes_tolerated']}}</value>
  </property>
  <property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value>31457280</value>
  </property>
  <property>
    <name>dfs.datanode.plugins</name>
    <value></value>
  </property>
  <property>
    <name>dfs.block.local-path-access.user</name>
    <value>impala,kpi</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit</name>
    <value>true</value>
  </property>
  <property>
    <name>dfs.domain.socket.path</name>
    <value>/var/run/hdfs-sockets/dn</value>
  </property>
  <property>
    <name>dfs.client.read.shortcircuit.skip.checksum</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.client.domain.socket.data.traffic</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.client.socket-timeout</name>
    <value>180000</value>
  </property>
  <property>
    <name>dfs.client.block.write.replace-datanode-on-failure.policy</name>
    <value>ALWAYS</value>
  </property>

</configuration>
